{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX2Oj9PL7zxC"
      },
      "source": [
        "### **Due Date**\n",
        "2/17/2025 at 11:59PM EST\n",
        "\n",
        "# **Introduction**\n",
        "\n",
        "Welcome to Assignment 2 of CS 4756/5756. In this assignment, you will train an agent using demonstrations from an expert. Concretely, you will:\n",
        "* Implement behavior cloning (BC)\n",
        "* **CS 5756 Only:** Implement dataset aggregation (DAgger)\n",
        "\n",
        "You will use the Fetch agent for this assignment (Reach task), which is part of Gymasium Robotics' Mujoco Environments. Refer to the Gym website for more details about the [Fetch Reach environment](https://robotics.farama.org/envs/fetch/reach/).\n",
        "\n",
        "\n",
        "Please read through the following paragraphs carefully, as they will apply to this and all future assignments.\n",
        "\n",
        "**Getting Started:** This assignment should be completed in [Google Colab](https://colab.research.google.com/). In order to visualize the environment rollouts, you may switch your runtime to the T4 GPU - however, it is not required for completion of the assignment.\n",
        "\n",
        "**Evaluation:**\n",
        "Your code will be tested for correctness and, for certain assignments, speed. For this particular assignment, performance results will not be harshly graded (although we provide approximate expected reward numbers as lower bounds, you are not expected to replicate them exactly); however, it will be important to make an effort to justify your approach which led to the obtained results. Please remember that all assignments should be completed individually.\n",
        "\n",
        "**Academic Integrity:** We will be checking your code against other submissions in the class for logical redundancy. If you copy someone else’s code and submit it with minor changes, we will know. These cheat detectors are quite hard to fool, so please don’t try. We trust you all to submit your own work only; please don’t let us down. If you do, we will pursue the strongest consequences available to us.\n",
        "\n",
        "**Getting Help:** The [Resources](https://www.cs.cornell.edu/courses/cs4756/2024sp/#resources) section on the course website is your friend! If you ever feel stuck in these projects, please feel free to avail yourself to office hours and Edstem! If you are unable to make any of the office hours listed, please let TAs know and we will be happy to assist. If you need a refresher for PyTorch, please see this [60 minute blitz](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)! For Numpy, please see the quickstart [here](https://numpy.org/doc/stable/user/quickstart.html) and full API [here](https://numpy.org/doc/stable/reference/).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stzlSyGe8TOU"
      },
      "source": [
        "# Installation and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4BBjyusBO-pE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04d46c07-544f-4568-a93b-9b592fb7f552",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cython<3\n",
            "  Downloading Cython-0.29.37-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (3.1 kB)\n",
            "Downloading Cython-0.29.37-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cython\n",
            "  Attempting uninstall: cython\n",
            "    Found existing installation: Cython 3.0.12\n",
            "    Uninstalling Cython-3.0.12:\n",
            "      Successfully uninstalled Cython-3.0.12\n",
            "Successfully installed cython-0.29.37\n",
            "Cloning into 'Gymnasium-Robotics'...\n",
            "remote: Enumerating objects: 7633, done.\u001b[K\n",
            "remote: Counting objects: 100% (2338/2338), done.\u001b[K\n",
            "remote: Compressing objects: 100% (594/594), done.\u001b[K\n",
            "remote: Total 7633 (delta 2042), reused 1777 (delta 1700), pack-reused 5295 (from 3)\u001b[K\n",
            "Receiving objects: 100% (7633/7633), 402.05 MiB | 37.43 MiB/s, done.\n",
            "Resolving deltas: 100% (4030/4030), done.\n",
            "Updating files: 100% (356/356), done.\n",
            "Obtaining file:///content/Gymnasium-Robotics\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mujoco>=2.2.0 (from gymnasium-robotics==1.3.1)\n",
            "  Downloading mujoco-3.2.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium-robotics==1.3.1) (1.26.4)\n",
            "Requirement already satisfied: gymnasium>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium-robotics==1.3.1) (1.0.0)\n",
            "Collecting PettingZoo>=1.23.0 (from gymnasium-robotics==1.3.1)\n",
            "  Downloading pettingzoo-1.24.3-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: Jinja2>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from gymnasium-robotics==1.3.1) (3.1.5)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (from gymnasium-robotics==1.3.1) (2.37.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->gymnasium-robotics==1.3.1) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->gymnasium-robotics==1.3.1) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->gymnasium-robotics==1.3.1) (0.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.0.3->gymnasium-robotics==1.3.1) (3.0.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mujoco>=2.2.0->gymnasium-robotics==1.3.1) (1.4.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.11/dist-packages (from mujoco>=2.2.0->gymnasium-robotics==1.3.1) (1.12.0)\n",
            "Collecting glfw (from mujoco>=2.2.0->gymnasium-robotics==1.3.1)\n",
            "  Downloading glfw-2.8.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.11/dist-packages (from mujoco>=2.2.0->gymnasium-robotics==1.3.1) (3.1.9)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio->gymnasium-robotics==1.3.1) (11.1.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco>=2.2.0->gymnasium-robotics==1.3.1) (2024.10.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco>=2.2.0->gymnasium-robotics==1.3.1) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco>=2.2.0->gymnasium-robotics==1.3.1) (3.21.0)\n",
            "Downloading mujoco-3.2.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pettingzoo-1.24.3-py3-none-any.whl (847 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m847.8/847.8 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading glfw-2.8.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: gymnasium-robotics\n",
            "  Building editable for gymnasium-robotics (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gymnasium-robotics: filename=gymnasium_robotics-1.3.1-0.editable-py3-none-any.whl size=7356 sha256=e822446f3b2bcd9a08422310a1ea81413fc332be80b5694e60dc58e9f6bac8c1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rrw3f57l/wheels/bc/45/9d/11a617e60b04ef39c544b7fa0f6698f8c6e22991f9d1aa14b0\n",
            "Successfully built gymnasium-robotics\n",
            "Installing collected packages: glfw, PettingZoo, mujoco, gymnasium-robotics\n",
            "Successfully installed PettingZoo-1.24.3 glfw-2.8.0 gymnasium-robotics-1.3.1 mujoco-3.2.7\n"
          ]
        }
      ],
      "source": [
        "!pip install \"cython<3\"\n",
        "!git clone https://github.com/Farama-Foundation/Gymnasium-Robotics.git\n",
        "!pip install -e Gymnasium-Robotics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uKHH-XGQW5aY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "26ad718e-057c-4da8-9e80-59bcd0252e99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '.mujoco_setup_complete': No such file or directory\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Selecting previously unselected package libglx-dev:amd64.\n",
            "(Reading database ... 124926 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libglx-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglx-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl-dev:amd64.\n",
            "Preparing to unpack .../01-libgl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libegl-dev:amd64.\n",
            "Preparing to unpack .../02-libegl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libegl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl1-mesa-glx:amd64.\n",
            "Preparing to unpack .../03-libgl1-mesa-glx_23.0.4-0ubuntu1~22.04.1_amd64.deb ...\n",
            "Unpacking libgl1-mesa-glx:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
            "Selecting previously unselected package libgles1:amd64.\n",
            "Preparing to unpack .../04-libgles1_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles1:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgles-dev:amd64.\n",
            "Preparing to unpack .../05-libgles-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglvnd-core-dev:amd64.\n",
            "Preparing to unpack .../06-libglvnd-core-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libopengl-dev:amd64.\n",
            "Preparing to unpack .../07-libopengl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglvnd-dev:amd64.\n",
            "Preparing to unpack .../08-libglvnd-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl1-mesa-dev:amd64.\n",
            "Preparing to unpack .../09-libgl1-mesa-dev_23.2.1-1ubuntu3.1~22.04.3_amd64.deb ...\n",
            "Unpacking libgl1-mesa-dev:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Selecting previously unselected package libglu1-mesa:amd64.\n",
            "Preparing to unpack .../10-libglu1-mesa_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package libglu1-mesa-dev:amd64.\n",
            "Preparing to unpack .../11-libglu1-mesa-dev_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package libglew-dev:amd64.\n",
            "Preparing to unpack .../12-libglew-dev_2.2.0-4_amd64.deb ...\n",
            "Unpacking libglew-dev:amd64 (2.2.0-4) ...\n",
            "Selecting previously unselected package libglfw3:amd64.\n",
            "Preparing to unpack .../13-libglfw3_3.3.6-1_amd64.deb ...\n",
            "Unpacking libglfw3:amd64 (3.3.6-1) ...\n",
            "Selecting previously unselected package patchelf.\n",
            "Preparing to unpack .../14-patchelf_0.14.3-1_amd64.deb ...\n",
            "Unpacking patchelf (0.14.3-1) ...\n",
            "Selecting previously unselected package libosmesa6:amd64.\n",
            "Preparing to unpack .../15-libosmesa6_23.2.1-1ubuntu3.1~22.04.3_amd64.deb ...\n",
            "Unpacking libosmesa6:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Selecting previously unselected package libosmesa6-dev:amd64.\n",
            "Preparing to unpack .../16-libosmesa6-dev_23.2.1-1ubuntu3.1~22.04.3_amd64.deb ...\n",
            "Unpacking libosmesa6-dev:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Setting up libglfw3:amd64 (3.3.6-1) ...\n",
            "Setting up libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libgles1:amd64 (1.4.0-1) ...\n",
            "Setting up libgl1-mesa-glx:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
            "Setting up libglx-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Setting up libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up patchelf (0.14.3-1) ...\n",
            "Setting up libgl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libosmesa6:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Setting up libegl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
            "Setting up libosmesa6-dev:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Setting up libgles-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libglew-dev:amd64 (2.2.0-4) ...\n",
            "Setting up libgl1-mesa-dev:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "Collecting mujoco-py<2.2,>=2.1\n",
            "  Downloading mujoco_py-2.1.2.14-py3-none-any.whl.metadata (669 bytes)\n",
            "Requirement already satisfied: glfw>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mujoco-py<2.2,>=2.1) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.11/dist-packages (from mujoco-py<2.2,>=2.1) (1.26.4)\n",
            "Requirement already satisfied: Cython>=0.27.2 in /usr/local/lib/python3.11/dist-packages (from mujoco-py<2.2,>=2.1) (0.29.37)\n",
            "Requirement already satisfied: imageio>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from mujoco-py<2.2,>=2.1) (2.37.0)\n",
            "Requirement already satisfied: cffi>=1.10 in /usr/local/lib/python3.11/dist-packages (from mujoco-py<2.2,>=2.1) (1.17.1)\n",
            "Collecting fasteners~=0.15 (from mujoco-py<2.2,>=2.1)\n",
            "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.10->mujoco-py<2.2,>=2.1) (2.22)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio>=2.1.2->mujoco-py<2.2,>=2.1) (11.1.0)\n",
            "Downloading mujoco_py-2.1.2.14-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fasteners, mujoco-py\n",
            "Successfully installed fasteners-0.19 mujoco-py-2.1.2.14\n",
            "Compiling /usr/local/lib/python3.11/dist-packages/mujoco_py/cymj.pyx because it changed.\n",
            "[1/1] Cythonizing /usr/local/lib/python3.11/dist-packages/mujoco_py/cymj.pyx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:running build_ext\n",
            "INFO:root:building 'mujoco_py.cymj' extension\n",
            "INFO:root:creating /usr/local/lib/python3.11/dist-packages/mujoco_py/generated/_pyxbld_2.1.2.14_311_linuxcpuextensionbuilder/temp.linux-x86_64-cpython-311/usr/local/lib/python3.11/dist-packages/mujoco_py\n",
            "INFO:root:creating /usr/local/lib/python3.11/dist-packages/mujoco_py/generated/_pyxbld_2.1.2.14_311_linuxcpuextensionbuilder/temp.linux-x86_64-cpython-311/usr/local/lib/python3.11/dist-packages/mujoco_py/gl\n",
            "INFO:root:x86_64-linux-gnu-gcc -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/mujoco_py -I/root/.mujoco/mujoco210/include -I/usr/local/lib/python3.11/dist-packages/numpy/core/include -I/usr/include/python3.11 -c /usr/local/lib/python3.11/dist-packages/mujoco_py/cymj.c -o /usr/local/lib/python3.11/dist-packages/mujoco_py/generated/_pyxbld_2.1.2.14_311_linuxcpuextensionbuilder/temp.linux-x86_64-cpython-311/usr/local/lib/python3.11/dist-packages/mujoco_py/cymj.o -fopenmp -w\n",
            "INFO:root:x86_64-linux-gnu-gcc -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/mujoco_py -I/root/.mujoco/mujoco210/include -I/usr/local/lib/python3.11/dist-packages/numpy/core/include -I/usr/include/python3.11 -c /usr/local/lib/python3.11/dist-packages/mujoco_py/gl/osmesashim.c -o /usr/local/lib/python3.11/dist-packages/mujoco_py/generated/_pyxbld_2.1.2.14_311_linuxcpuextensionbuilder/temp.linux-x86_64-cpython-311/usr/local/lib/python3.11/dist-packages/mujoco_py/gl/osmesashim.o -fopenmp -w\n",
            "INFO:root:creating /usr/local/lib/python3.11/dist-packages/mujoco_py/generated/_pyxbld_2.1.2.14_311_linuxcpuextensionbuilder/lib.linux-x86_64-cpython-311/mujoco_py\n",
            "INFO:root:x86_64-linux-gnu-gcc -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 /usr/local/lib/python3.11/dist-packages/mujoco_py/generated/_pyxbld_2.1.2.14_311_linuxcpuextensionbuilder/temp.linux-x86_64-cpython-311/usr/local/lib/python3.11/dist-packages/mujoco_py/cymj.o /usr/local/lib/python3.11/dist-packages/mujoco_py/generated/_pyxbld_2.1.2.14_311_linuxcpuextensionbuilder/temp.linux-x86_64-cpython-311/usr/local/lib/python3.11/dist-packages/mujoco_py/gl/osmesashim.o -L/root/.mujoco/mujoco210/bin -L/usr/lib/x86_64-linux-gnu -Wl,--enable-new-dtags,-rpath,/root/.mujoco/mujoco210/bin -lmujoco210 -lglewosmesa -lOSMesa -lGL -o /usr/local/lib/python3.11/dist-packages/mujoco_py/generated/_pyxbld_2.1.2.14_311_linuxcpuextensionbuilder/lib.linux-x86_64-cpython-311/mujoco_py/cymj.cpython-311-x86_64-linux-gnu.so -fopenmp\n"
          ]
        }
      ],
      "source": [
        "#Include this at the top of your colab code\n",
        "import os\n",
        "!rm .mujoco_setup_complete\n",
        "if not os.path.exists('.mujoco_setup_complete'):\n",
        "  # Get the prereqs\n",
        "  !apt-get -qq update\n",
        "  !apt-get -qq install -y libosmesa6-dev libgl1-mesa-glx libglfw3 libgl1-mesa-dev libglew-dev patchelf\n",
        "  # Get Mujoco\n",
        "  !rm -rf ~/.mujoco\n",
        "  !mkdir ~/.mujoco\n",
        "  !wget -q https://mujoco.org/download/mujoco210-linux-x86_64.tar.gz -O mujoco.tar.gz\n",
        "  !tar -zxf mujoco.tar.gz -C \"$HOME/.mujoco\"\n",
        "  !rm mujoco.tar.gz\n",
        "  # Add it to the actively loaded path and the bashrc path (these only do so much)\n",
        "  !echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HOME/.mujoco/mujoco210/bin' >> ~/.bashrc\n",
        "  !echo 'export LD_PRELOAD=$LD_PRELOAD:/usr/lib/x86_64-linux-gnu/libGLEW.so' >> ~/.bashrc\n",
        "  # THE ANNOYING ONE, FORCE IT INTO LDCONFIG SO WE ACTUALLY GET ACCESS TO IT THIS SESSION\n",
        "  !echo \"/root/.mujoco/mujoco210/bin\" > /etc/ld.so.conf.d/mujoco_ld_lib_path.conf\n",
        "  !ldconfig\n",
        "  # Install Mujoco-py\n",
        "  !pip3 install -U 'mujoco-py<2.2,>=2.1'\n",
        "  # run once\n",
        "  !touch .mujoco_setup_complete\n",
        "\n",
        "\n",
        "try:\n",
        "  if _mujoco_run_once:\n",
        "    pass\n",
        "except NameError:\n",
        "  _mujoco_run_once = False\n",
        "if not _mujoco_run_once:\n",
        "  # Add it to the actively loaded path and the bashrc path (these only do so much)\n",
        "  try:\n",
        "    os.environ['LD_LIBRARY_PATH']=os.environ['LD_LIBRARY_PATH'] + ':/root/.mujoco/mujoco210/bin'\n",
        "  except KeyError:\n",
        "    os.environ['LD_LIBRARY_PATH']='/root/.mujoco/mujoco210/bin'\n",
        "  try:\n",
        "    os.environ['LD_PRELOAD']=os.environ['LD_PRELOAD'] + ':/usr/lib/x86_64-linux-gnu/libGLEW.so'\n",
        "  except KeyError:\n",
        "    os.environ['LD_PRELOAD']='/usr/lib/x86_64-linux-gnu/libGLEW.so'\n",
        "  # presetup so we don't see output on first env initialization\n",
        "  import mujoco_py\n",
        "  _mujoco_run_once = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y07C0IpATP7S"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is available\")\n",
        "    !pip install mujoco\n",
        "\n",
        "    # Set up GPU rendering.\n",
        "    from google.colab import files\n",
        "    import distutils.util\n",
        "    import os\n",
        "    import subprocess\n",
        "    if subprocess.run('nvidia-smi').returncode:\n",
        "        raise RuntimeError(\n",
        "            'Cannot communicate with GPU. '\n",
        "            'Make sure you are using a GPU Colab runtime. '\n",
        "            'Go to the Runtime menu and select Choose runtime type.')\n",
        "\n",
        "    # Add an ICD config so that glvnd can pick up the Nvidia EGL driver.\n",
        "    # This is usually installed as part of an Nvidia driver package, but the Colab\n",
        "    # kernel doesn't install its driver via APT, and as a result the ICD is missing.\n",
        "    # (https://github.com/NVIDIA/libglvnd/blob/master/src/EGL/icd_enumeration.md)\n",
        "    NVIDIA_ICD_CONFIG_PATH = '/usr/share/glvnd/egl_vendor.d/10_nvidia.json'\n",
        "    if not os.path.exists(NVIDIA_ICD_CONFIG_PATH):\n",
        "        with open(NVIDIA_ICD_CONFIG_PATH, 'w') as f:\n",
        "            f.write(\"\"\"{\n",
        "            \"file_format_version\" : \"1.0.0\",\n",
        "            \"ICD\" : {\n",
        "                \"library_path\" : \"libEGL_nvidia.so.0\"\n",
        "            }\n",
        "        }\n",
        "        \"\"\")\n",
        "\n",
        "    # Configure MuJoCo to use the EGL rendering backend (requires GPU)\n",
        "    print('Setting environment variable to use GPU rendering:')\n",
        "    %env MUJOCO_GL=egl\n",
        "\n",
        "    # Check if installation was succesful.\n",
        "    try:\n",
        "        print('Checking that the installation succeeded:')\n",
        "        import mujoco\n",
        "        mujoco.MjModel.from_xml_string('<mujoco/>')\n",
        "    except Exception as e:\n",
        "        raise e from RuntimeError(\n",
        "            'Something went wrong during installation. Check the shell output above '\n",
        "            'for more information.\\n'\n",
        "            'If using a hosted Colab runtime, make sure you enable GPU acceleration '\n",
        "            'by going to the Runtime menu and selecting \"Choose runtime type\".')\n",
        "\n",
        "    print('Installation successful.')\n",
        "\n",
        "    # Other imports and helper functions\n",
        "    import time\n",
        "    import itertools\n",
        "    import numpy as np\n",
        "\n",
        "    # Graphics and plotting.\n",
        "    print('Installing mediapy:')\n",
        "    !command -v ffmpeg >/dev/null || (apt update && apt install -y ffmpeg)\n",
        "    !pip install -q mediapy\n",
        "    import mediapy as media\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # More legible printing from numpy.\n",
        "    np.set_printoptions(precision=3, suppress=True, linewidth=100)\n",
        "\n",
        "    from IPython.display import clear_output\n",
        "    clear_output()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o68xk-XVP43Z",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "!pip install renderlab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUR0dp_RPE7k"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/Gymnasium-Robotics')\n",
        "import gymnasium as gym\n",
        "import gymnasium_robotics\n",
        "import renderlab as rl\n",
        "\n",
        "ROBOT_PROPRIOCEPTION_KEY = 'observation'\n",
        "ROBOT_XYZ_GOAL_KEY = 'desired_goal'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqbGVz9z8Zo8"
      },
      "source": [
        "### **Downloading Expert File**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqYWlZSgbroN"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/kuanfang/cornell-cs4756-2025sp/raw/main/assignments/A1/programming/expert.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJczc-qw8rJ6"
      },
      "source": [
        "# **Environment and Expert Setup**\n",
        "The environment is held in ```env``` and the expert agent is held in ```actor_network```.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcJtRqVSPh31"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def process_inputs(o, g, o_mean, o_std, g_mean, g_std, clip_obs, clip_range):\n",
        "    o_clip = np.clip(o, -clip_obs, clip_obs)\n",
        "    g_clip = np.clip(g, -clip_obs, clip_obs)\n",
        "    o_norm = np.clip((o_clip - o_mean) / (o_std), -clip_range, clip_range)\n",
        "    g_norm = np.clip((g_clip - g_mean) / (g_std), -clip_range, clip_range)\n",
        "    inputs = np.concatenate([o_norm, g_norm])\n",
        "    inputs = torch.tensor(inputs, dtype=torch.float32)\n",
        "    return inputs\n",
        "\n",
        "\n",
        "# define the Expert network\n",
        "class Expert(nn.Module):\n",
        "    def __init__(self, env_params, o_mean, o_std, g_mean, g_std):\n",
        "        super(Expert, self).__init__()\n",
        "        self.max_action = env_params['action_max']\n",
        "        self.fc1 = nn.Linear(env_params[ROBOT_PROPRIOCEPTION_KEY] + env_params[ROBOT_XYZ_GOAL_KEY], 256)\n",
        "        self.fc2 = nn.Linear(256, 256)\n",
        "        self.fc3 = nn.Linear(256, 256)\n",
        "        self.action_out = nn.Linear(256, env_params['action'])\n",
        "        self.o_mean = o_mean\n",
        "        self.o_std = o_std\n",
        "        self.g_mean = g_mean\n",
        "        self.g_std = g_std\n",
        "        self.clip_obs = 200\n",
        "        self.clip_range = 5\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        actions = self.max_action * torch.tanh(self.action_out(x))\n",
        "\n",
        "        return actions\n",
        "\n",
        "    def get_expert_action(self, prop, g):\n",
        "        inputs = process_inputs(prop, g, self.o_mean, self.o_std, self.g_mean, self.g_std, self.clip_obs, self.clip_range).to(device)\n",
        "        pi = self.forward(inputs)\n",
        "        action = pi.detach().cpu().numpy().squeeze()\n",
        "        return action\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxFod0nzpU1G"
      },
      "source": [
        "## **Notes about Fetch Reach Environment**\n",
        "The environment uses a Fetch Robot, which is a 7-DoF Mobile Manipulator.\n",
        "\n",
        "The task is a *goal-reaching task*:\n",
        "The observation space is a dictionary which contains the robot's proprioception (under the key `ROBOT_PROPRIOCEPTION_KEY`), and the xyz coordinate that the robot's gripper aims to reach (under the key `ROBOT_GOAL_XYZ_KEY`).\n",
        "\n",
        "All agents have functions defined which take the two pieces of data in order to predict an action to take.\n",
        "\n",
        "See https://robotics.farama.org/envs/fetch/reach/ for more details.\n",
        "\n",
        "If the goal is reached, `info['is_success']` will be set to 1, and this is an indication that we should terminate the rollout.\n",
        "\n",
        "The reward (used only for evaluation in this assignment) is -1 per timestep spent in the environment without completing the task, with 50 steps being the limit (so -50 is the worst episode return)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_L5P4YnT6Aa"
      },
      "outputs": [],
      "source": [
        "print(device)\n",
        "model_path = \"expert.pt\"\n",
        "o_mean, o_std, g_mean, g_std, model = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
        "model\n",
        "# create the environment\n",
        "env = gym.make('FetchReach-v4', render_mode='rgb_array')# get the env param\n",
        "observation, _ = env.reset()\n",
        "\n",
        "# get the environment params\n",
        "env_params = {ROBOT_PROPRIOCEPTION_KEY: observation[ROBOT_PROPRIOCEPTION_KEY].shape[0],\n",
        "                ROBOT_XYZ_GOAL_KEY: observation[ROBOT_XYZ_GOAL_KEY].shape[0],\n",
        "                'action': env.action_space.shape[0],\n",
        "                'action_max': env.action_space.high[0],\n",
        "                }\n",
        "# create the Expert network\n",
        "expert_network = Expert(env_params, o_mean, o_std, g_mean, g_std)\n",
        "expert_network.to(device)\n",
        "expert_network.load_state_dict(model)\n",
        "expert_network.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9HT4r0jPZWn"
      },
      "outputs": [],
      "source": [
        "import mujoco_py\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import tqdm\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.optim import optimizer\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display as ipythondisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvprulQEPbqs"
      },
      "outputs": [],
      "source": [
        "# Setting the seed to ensure reproducability\n",
        "def reseed(seed):\n",
        "  torch.manual_seed(seed)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "\n",
        "reseed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_qBssuw9BIJ"
      },
      "source": [
        "# **Example Demonstration Rollouts**\n",
        "### **Visualizing the Fetch Reach environment**\n",
        "\n",
        "We have provided functions to visualize the environment and compute rewards on the Fetch Reach environment with random actions or expert actions. Looking through this code will help you get familiarized with the environment, and set you up for the next parts in this assignment.\n",
        "\n",
        "We disabled the visualizations by default since they greatly slow down the evaluation, but feel free to turn it on if you're interested. You'll have to set visualize to True in the cell below and render_mode to 'rgb_array' when setting up the environment. Note that visualization will only be possible if T4 GPU runtime is available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28GY6jO3O3z7"
      },
      "outputs": [],
      "source": [
        "NUM_TRAJS = 10\n",
        "visualize = False and torch.cuda.is_available() # set to false in order to disable rendering code\n",
        "if visualize:\n",
        "    env = rl.RenderFrame(env, './output')\n",
        "if visualize:\n",
        "    plt.axis('off')\n",
        "total_reward_random = 0\n",
        "i = 0\n",
        "\n",
        "for k in range(NUM_TRAJS):\n",
        "  done = False\n",
        "  observation, info = env.reset(seed = k)\n",
        "  while not done:\n",
        "    i += 1\n",
        "    if visualize and i%5==0:\n",
        "      ipythondisplay.clear_output(wait=True)\n",
        "      screen = env.render()\n",
        "      plt.imshow(screen)\n",
        "      ipythondisplay.display(plt.gcf())\n",
        "    action = env.action_space.sample()\n",
        "    observation, reward, terminated, truncated, info = env.step(action)\n",
        "    done = terminated or truncated or info['is_success']\n",
        "    total_reward_random += reward\n",
        "    if done:\n",
        "        break\n",
        "total_reward_random /= NUM_TRAJS\n",
        "print(f\"Avg Reward using Random Actions = \", (total_reward_random))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oAYUuYevOZh"
      },
      "outputs": [],
      "source": [
        "NUM_TRAJS = 10\n",
        "visualize = True and torch.cuda.is_available() # set to false in order to disable rendering code\n",
        "if visualize:\n",
        "    env = rl.RenderFrame(env, './output')\n",
        "if visualize:\n",
        "    plt.axis('off')\n",
        "total_reward = 0\n",
        "i = 0\n",
        "\n",
        "for k in range(NUM_TRAJS):\n",
        "  done = False\n",
        "  observation, info = env.reset(seed = k)\n",
        "  while not done:\n",
        "    i += 1\n",
        "    if visualize and i%5==0:\n",
        "      ipythondisplay.clear_output(wait=True)\n",
        "      screen = env.render()\n",
        "      plt.imshow(screen)\n",
        "      ipythondisplay.display(plt.gcf())\n",
        "    action = expert_network.get_expert_action(observation[ROBOT_PROPRIOCEPTION_KEY], observation[ROBOT_XYZ_GOAL_KEY])\n",
        "    observation, reward, terminated, truncated, info = env.step(action)\n",
        "    done = terminated or truncated or info['is_success']\n",
        "    total_reward += reward\n",
        "    if done:\n",
        "        break\n",
        "total_reward /= NUM_TRAJS\n",
        "print(f\"Avg Reward using Expert Actions = \", (total_reward))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW8o41mxo59n"
      },
      "source": [
        "**Approximate expected reward for total reward using random actions: -40 to -50**\n",
        "\n",
        "**Approximate expected reward for total reward using expert actions: -2 to -3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UD1ZHLTM9HYG"
      },
      "source": [
        "# **Defining Learner Agent Class**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hhnpo76JY24y"
      },
      "outputs": [],
      "source": [
        "class Learner(nn.Module):\n",
        "    def __init__(self, env, env_params, hidden_dim = 256, random_prob=0.0):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(env_params[ROBOT_PROPRIOCEPTION_KEY] + env_params[ROBOT_XYZ_GOAL_KEY], hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc_out = nn.Linear(hidden_dim, env_params['action'])\n",
        "\n",
        "        self.env = env\n",
        "        self.random_prob = random_prob\n",
        "\n",
        "    def forward(self, prop, g):\n",
        "        x = torch.cat([prop, g], dim=-1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        out = F.tanh(self.fc_out(x))\n",
        "        return out\n",
        "\n",
        "    def get_action(self, prop, g):\n",
        "        if np.random.random() < self.random_prob:\n",
        "            return self.env.action_space.sample()\n",
        "        action = self.forward(torch.tensor(prop).unsqueeze(0).to(device).float(), torch.tensor(g).unsqueeze(0).to(device).float())\n",
        "        return np.array(action[0].detach().cpu())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_XStdq5dbbP"
      },
      "outputs": [],
      "source": [
        "def get_checkpoint_path(algo):\n",
        "    \"\"\"Return the path to save the best performing model checkpoint.\n",
        "\n",
        "    Parameters:\n",
        "        algo (str)\n",
        "          Indicates which algorithm will be used to train the model\n",
        "\n",
        "    Returns:\n",
        "        checkpoint_path (str)\n",
        "            The path to save the best performing model checkpoint\n",
        "    \"\"\"\n",
        "    if algo == \"bc\":\n",
        "      return 'best_bc_checkpoint.pth'\n",
        "    elif algo == \"dagger\":\n",
        "      return 'best_dagger_checkpoint.pth'\n",
        "    return 'best_model_checkpoint.pth'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WG0nfNoc9hdU"
      },
      "source": [
        "# **Collect Expert Demonstrations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmomR2K7ddeq"
      },
      "outputs": [],
      "source": [
        "### Collecting trajectories (i.e. demonstrations) using the expert policy\n",
        "NUM_TRAJS = 12\n",
        "proprios, goals, actions = [], [], []\n",
        "reseed(1)\n",
        "for traj_num in tqdm(range(NUM_TRAJS), position=0, leave=True):\n",
        "    done = False\n",
        "    observation, _ = env.reset(seed = traj_num)\n",
        "    while not done:\n",
        "        with torch.no_grad():\n",
        "            action = expert_network.get_expert_action(observation[ROBOT_PROPRIOCEPTION_KEY], observation[ROBOT_XYZ_GOAL_KEY])\n",
        "            proprios.append(observation[ROBOT_PROPRIOCEPTION_KEY])\n",
        "            goals.append(observation[ROBOT_XYZ_GOAL_KEY])\n",
        "            action[-1] = 0\n",
        "            actions.append(action)\n",
        "            observation, reward, terminated, truncated, info = env.step(action)\n",
        "            done = terminated or truncated or info['is_success']\n",
        "        if done:\n",
        "            break\n",
        "train_proprios = proprios[:int(0.5*len(proprios))]\n",
        "train_goals = goals[:int(0.5*len(proprios))]\n",
        "train_actions = actions[:int(0.5*len(actions))]\n",
        "validation_proprios = proprios[int(0.5*len(proprios)):]\n",
        "validation_goals = goals[int(0.5*len(proprios)):]\n",
        "validation_actions = actions[int(0.5*len(actions)):]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-C_Gzco9l9p"
      },
      "source": [
        "# PART 1: (CS 4756/5756) **Implement and train BC Agent**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZCo8xmxrGjj"
      },
      "source": [
        "To begin, fill in the implementation for the training loop function in **`bc_train`**. We provide the loss function and optimizer already, just iterate through your dataloader and return the updated policy!\n",
        "\n",
        "You'll also measure the validation loss at each iteration to check for overfitting.\n",
        "\n",
        "Once you finish the training loop implementation, it is now time to build up your agents! **Behavior cloning (BC)** is the simplest imitation learning algorithm, where we perform supervised learning on the given (offline) expert dataset. We either do this via log-likelihood maximization (cross-entropy minimization) in the discrete action case, or mean-squared error minimization (can also do MLE) in the continuous control setting.\n",
        "\n",
        "If implemented correctly, training your BC model should take at most 1 minute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "HZemVLJsl7Uh"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import tqdm\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.optim import optimizer\n",
        "\n",
        "def evaluate(env, learner):\n",
        "    NUM_TRAJS = 20\n",
        "    total_learner_reward = 0\n",
        "    for i in range(NUM_TRAJS):\n",
        "        done = False\n",
        "        observation, _ = env.reset(seed = i)\n",
        "        while not done:\n",
        "            action = learner.get_action(observation[ROBOT_PROPRIOCEPTION_KEY], observation[ROBOT_XYZ_GOAL_KEY])\n",
        "            observation, reward, terminated, truncated, info = env.step(action)\n",
        "            done = terminated or truncated or info['is_success']\n",
        "            total_learner_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "    return total_learner_reward / NUM_TRAJS\n",
        "\n",
        "def bc_train(learner, proprios, goals, actions, validation_proprios, validation_goals, validation_acts, checkpoint_path, num_epochs=100):\n",
        "    \"\"\"Train function for learning a new policy using BC.\n",
        "\n",
        "    Parameters:\n",
        "        learner (Learner)\n",
        "            A Learner object (policy)\n",
        "        proprios (list of torch.tensor)\n",
        "            A list of pytorch arrays of shape (N, 10, )\n",
        "        goals (list of torch.tensor)\n",
        "            A list of pytorch arrays of shape (N, 3, )\n",
        "        actions (list of torch.tensor)\n",
        "            A list of pytorch arrays of shape (N, 4, )\n",
        "        checkpoint_path (str)\n",
        "            The path to save the best performing checkpoint\n",
        "        num_epochs (int)\n",
        "            Number of epochs to run the train function for\n",
        "\n",
        "    Returns:\n",
        "        learner (Learner)\n",
        "            A Learner object (policy)\n",
        "    \"\"\"\n",
        "    best_loss = float('inf')\n",
        "    best_model_state = None\n",
        "\n",
        "    loss_fn = torch.nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(learner.parameters(), lr=3e-4)\n",
        "    dataset = TensorDataset(proprios, goals, actions) # Create your dataset\n",
        "    dataloader = DataLoader(dataset, batch_size=256, shuffle=True) # Create your dataloader\n",
        "\n",
        "    # TODO: Complete the training loop here ###\n",
        "    loss = float('inf')\n",
        "    validation_losses = []\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        epoch_loss = 0\n",
        "        for batch_idx, (prop, g, act) in enumerate(dataloader):\n",
        "            optimizer.zero_grad()\n",
        "            predicted_actions = learner(prop, g)\n",
        "            loss = loss_fn(predicted_actions, act)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            validation_loss = loss_fn(learner(validation_proprios, validation_goals), validation_acts)\n",
        "            validation_losses.append(validation_loss)\n",
        "\n",
        "        if epoch_loss < best_loss:\n",
        "            best_loss = epoch_loss\n",
        "            torch.save(learner.state_dict().copy(), checkpoint_path)\n",
        "    if checkpoint_path == 'best_bc_checkpoint.pth':\n",
        "        plt.plot(np.arange(0, num_epochs), [t.cpu().numpy() if isinstance(t, torch.Tensor) else t for t in validation_losses])\n",
        "        plt.title(\"Validation Loss vs. Iteration\")\n",
        "        plt.xlabel(\"Iteration\")\n",
        "        plt.ylabel(\"Validation Loss\")\n",
        "        plt.savefig(\"BC_validation_loss.png\")\n",
        "\n",
        "    return learner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GPQkFimrgnw"
      },
      "source": [
        "The resulting graph should show a clear downward trend without curving back up at the right side. If the validation loss increases at the end, it indicates overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "bTVYj5MJmGBh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "outputId": "00ee516b-98ef-4083-8d09-aa9f338c746b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1500/1500 [00:10<00:00, 140.51it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Learner(\n",
              "  (fc1): Linear(in_features=13, out_features=256, bias=True)\n",
              "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (fc_out): Linear(in_features=256, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "bc_learner = Learner(env, env_params)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "bc_learner.to(device)\n",
        "checkpoint_path = get_checkpoint_path(\"bc\")\n",
        "reseed(2)\n",
        "bc_train(\n",
        "    bc_learner,\n",
        "    torch.tensor(train_proprios).to(device).float(),\n",
        "    torch.tensor(train_goals).to(device).float(),\n",
        "    torch.tensor(train_actions).to(device).float(),\n",
        "    torch.tensor(validation_proprios).to(device).float(),\n",
        "    torch.tensor(validation_goals).to(device).float(),\n",
        "    torch.tensor(validation_actions).to(device).float(),\n",
        "    checkpoint_path,\n",
        "    num_epochs = 1500\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgUQ8gxorl01"
      },
      "source": [
        "### Evaluate the BC Agent's Performance\n",
        "**Approximate expected reward for BC learner: -10 to -15**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "xLTLV-wTn9_A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "015fdf2b-b67c-49d5-c9b9-5984b2ed4a8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:<ipython-input-25-2209cc39273a>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bc_learner.load_state_dict(torch.load(checkpoint_path))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avg Reward using Learner Actions =  -11.5\n",
            "Avg Reward using Expert Actions =  -1.8\n"
          ]
        }
      ],
      "source": [
        "bc_learner = Learner(env, env_params)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "bc_learner.to(device)\n",
        "checkpoint_path = get_checkpoint_path(\"bc\")\n",
        "bc_learner.load_state_dict(torch.load(checkpoint_path))\n",
        "bc_learner.eval()\n",
        "\n",
        "print(\"Avg Reward using Learner Actions = \", (evaluate(env, bc_learner)))\n",
        "print(\"Avg Reward using Expert Actions = \", (total_reward))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcULu9NS91A7"
      },
      "source": [
        "# PART 2: (CS 5756 Only) **Implement and train DAgger Agent**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQuFeDwmsJnA"
      },
      "source": [
        "**Dataset aggregation (DAgger)** is a fundamentally interactive algorithm, where we can query the expert any time we want to get information about how to proceed. This allows for significantly more freedom for the learner, as it can ask the expert anywhere and not be limited by the dataset that it is given to learn from.\n",
        "\n",
        "**Can we overcome suboptimal actions with DAgger?** Fundamentally, this algorithm allows the learner to recover from bad states and should lead to much better performance than simply behavior cloning a fixed set of expert demonstrations. For this portion of the assignment, you will interact with the environment using the learner policy with random actions. You will do so in **`interact`**.\n",
        "\n",
        "The DAgger policy will be initialized with the already learned BC policy and your dataset with the already collected expert demonstrations for BC.\n",
        "\n",
        "Training should take no longer than 2 minutes if implemented correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ysZJk_Cawvjw"
      },
      "outputs": [],
      "source": [
        "def interact(env, learner, expert_network, proprios, goals, actions, validation_proprios, validation_goals, validation_actions, checkpoint_path, seed, num_epochs=100, horizon=50):\n",
        "    \"\"\"Interact with the environment and update the learner policy using DAgger.\n",
        "\n",
        "    This function interacts with the given Gym environment and aggregates to\n",
        "    the BC dataset by querying the expert.\n",
        "\n",
        "    Parameters:\n",
        "        env (Env)\n",
        "            The gym environment (in this case, the Hopper gym environment)\n",
        "        learner (Learner)\n",
        "            A Learner object (policy)\n",
        "        expert_network (Expert)\n",
        "            An Expert object (expert policy)\n",
        "        proprios (list of torch.tensor)\n",
        "            A list of pytorch arrays of shape (N, 10, )\n",
        "        goals (list of torch.tensor)\n",
        "            A list of pytorch arrays of shape (N, 3, )\n",
        "        actions (list of torch.tensor)\n",
        "            A list of pytorch arrays of shape (N, 4, )\n",
        "        checkpoint_path (str)\n",
        "            The path to save the best performing model checkpoint\n",
        "        seed (int)\n",
        "            The seed to use for the environment\n",
        "        num_epochs (int)\n",
        "            Number of epochs to run the train function for\n",
        "    \"\"\"\n",
        "    NUM_INTERACTIONS = 9\n",
        "    best_reward = float('-inf')\n",
        "    best_model_state = None\n",
        "    for episode in range(NUM_INTERACTIONS):\n",
        "        for _ in range(2):\n",
        "            done = False\n",
        "            observation, _ = env.reset(seed = episode)\n",
        "            for _ in range(horizon):\n",
        "                # TODO: Implement Fetch Reach environment interaction and dataset aggregation here\n",
        "                #BEGIN SOLUTION\n",
        "                action = learner.get_action(observation[ROBOT_PROPRIOCEPTION_KEY], observation[ROBOT_XYZ_GOAL_KEY])\n",
        "                proprios = proprios.cpu() if isinstance(proprios, torch.Tensor) else proprios\n",
        "                goals = goals.cpu() if isinstance(goals, torch.Tensor) else goals\n",
        "                actions = actions.cpu() if isinstance(actions, torch.Tensor) else actions\n",
        "\n",
        "                proprios = proprios.tolist() if isinstance(proprios, torch.Tensor) else proprios\n",
        "                goals = goals.tolist() if isinstance(goals, torch.Tensor) else goals\n",
        "                actions = actions.tolist() if isinstance(actions, torch.Tensor) else actions\n",
        "\n",
        "                proprios.append(observation[ROBOT_PROPRIOCEPTION_KEY])\n",
        "                goals.append(observation[ROBOT_XYZ_GOAL_KEY])\n",
        "\n",
        "                expert_action = expert_network.get_expert_action(observation[ROBOT_PROPRIOCEPTION_KEY], observation[ROBOT_XYZ_GOAL_KEY])\n",
        "                actions.append(expert_action)\n",
        "\n",
        "                observation, reward, terminated, truncated, info = env.step(action)\n",
        "                done = terminated or truncated or info['is_success']\n",
        "                #END SOLUTION\n",
        "                if done:\n",
        "                    break\n",
        "        bc_train(learner,\n",
        "                 torch.tensor(proprios).to(device).float(),\n",
        "                torch.tensor(goals).to(device).float(),\n",
        "                torch.tensor(actions).to(device).float(),\n",
        "                torch.tensor(validation_proprios).to(device).float(),\n",
        "                torch.tensor(validation_goals).to(device).float(),\n",
        "                torch.tensor(validation_actions).to(device).float(),\n",
        "                 \"DAgger_Interaction_{}.pth\".format(episode), num_epochs)\n",
        "        reward = evaluate(env, learner)\n",
        "        print(f\"After interaction {episode}, reward = {reward}\")\n",
        "        if reward > best_reward:\n",
        "            best_reward = reward\n",
        "            torch.save(learner.state_dict().copy(), checkpoint_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WMuceBCwWro"
      },
      "source": [
        "**Approximate expected reward for DAgger learner: -4 to -8**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "tmUVp6iRzYaz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45409400-de1f-4a90-bde0-1c1ba32684c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:<ipython-input-27-36c3d21b3d82>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  dagger_learner.load_state_dict(torch.load(checkpoint_path))\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Learner(\n",
              "  (fc1): Linear(in_features=13, out_features=256, bias=True)\n",
              "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (fc_out): Linear(in_features=256, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Initialize DAgger Agent with BC learner's weights\n",
        "dagger_learner = Learner(env, env_params)\n",
        "checkpoint_path = get_checkpoint_path(\"bc\")\n",
        "dagger_learner.load_state_dict(torch.load(checkpoint_path))\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "dagger_learner.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "eQTRN4i9zhnn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16e70f39-f2b7-4bf9-a3e0-0fe275191e33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:<ipython-input-26-8fc2357e0d99>:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(validation_proprios).to(device).float(),\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-26-8fc2357e0d99>:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(validation_goals).to(device).float(),\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-26-8fc2357e0d99>:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(validation_actions).to(device).float(),\n",
            "\n",
            "100%|██████████| 500/500 [00:01<00:00, 276.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After interaction 0, reward = -18.6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:01<00:00, 266.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After interaction 1, reward = -18.6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:01<00:00, 271.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After interaction 2, reward = -18.55\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:01<00:00, 279.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After interaction 3, reward = -18.55\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:01<00:00, 273.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After interaction 4, reward = -18.55\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:01<00:00, 284.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After interaction 5, reward = -18.55\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:01<00:00, 259.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After interaction 6, reward = -13.8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:02<00:00, 219.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After interaction 7, reward = -6.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:02<00:00, 174.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After interaction 8, reward = -4.8\n"
          ]
        }
      ],
      "source": [
        "checkpoint_path = get_checkpoint_path(\"dagger\")\n",
        "seed = 2\n",
        "reseed(seed)\n",
        "interact(env, dagger_learner, expert_network, torch.tensor(train_proprios).to(device), torch.tensor(train_goals).to(device), torch.tensor(train_actions).to(device), torch.tensor(validation_proprios).to(device), torch.tensor(validation_goals), torch.tensor(validation_actions).to(device), checkpoint_path, seed, num_epochs = 500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "X1x0FNAooLw7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb254808-9c10-4180-b6a5-6c53fb887fa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:<ipython-input-29-e16f7c98ee98>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  dagger_learner.load_state_dict(torch.load(checkpoint_path))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avg Reward using DAgger Learner Actions =  -4.8\n",
            "Avg Reward using Expert Actions =  -1.8\n"
          ]
        }
      ],
      "source": [
        "dagger_learner = Learner(env, env_params)\n",
        "checkpoint_path = get_checkpoint_path(\"dagger\")\n",
        "dagger_learner.load_state_dict(torch.load(checkpoint_path))\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "dagger_learner.to(device)\n",
        "dagger_learner.eval()\n",
        "\n",
        "print(\"Avg Reward using DAgger Learner Actions = \", (evaluate(env, dagger_learner)))\n",
        "print(\"Avg Reward using Expert Actions = \", (total_reward))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1877kA6tMaj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "stzlSyGe8TOU"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}